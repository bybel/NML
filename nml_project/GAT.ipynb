{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094b4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09f820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf5e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install gputil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import GPUtil\n",
    "import time\n",
    "\n",
    "def monitor_gpu(seconds=5):\n",
    "    \"\"\"Monitor GPU usage every n seconds\"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            GPUtil.showUtilization()\n",
    "            print('-' * 40)\n",
    "            time.sleep(seconds)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Monitoring stopped.\")\n",
    "\n",
    "# Check if GPU is available and print info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Usage:\")\n",
    "    print(f\"Allocated: {round(torch.cuda.memory_allocated(0)/1024**3, 1)} GB\")\n",
    "    print(f\"Cached: {round(torch.cuda.memory_reserved(0)/1024**3, 1)} GB\")\n",
    "\n",
    "# To use, run in a separate cell and press Ctrl+C to stop when done\n",
    "# monitor_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4917039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec02bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>date</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>signals_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pqejgcff_s001_t000_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcff_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcff_s001_t000_1</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcff_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcff_s001_t000_2</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcff_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcff_s001_t000_3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcff_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcff_s001_t000_4</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcff_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvqb_s001_t013_8</th>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvqb_s001_t013.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvqb_s001_t013_9</th>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvqb_s001_t013.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvqb_s001_t013_10</th>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvqb_s001_t013.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvqb_s001_t013_11</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvqb_s001_t013.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvqb_s001_t013_12</th>\n",
       "      <td>0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvqb_s001_t013.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12993 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  start_time  end_time       date  sampling_rate  \\\n",
       "id                                                                             \n",
       "pqejgcff_s001_t000_0       1         0.0      12.0 2003-01-01            250   \n",
       "pqejgcff_s001_t000_1       1        12.0      24.0 2003-01-01            250   \n",
       "pqejgcff_s001_t000_2       1        24.0      36.0 2003-01-01            250   \n",
       "pqejgcff_s001_t000_3       1        36.0      48.0 2003-01-01            250   \n",
       "pqejgcff_s001_t000_4       1        48.0      60.0 2003-01-01            250   \n",
       "...                      ...         ...       ...        ...            ...   \n",
       "pqejgvqb_s001_t013_8       1        96.0     108.0 2015-01-01            250   \n",
       "pqejgvqb_s001_t013_9       1       108.0     120.0 2015-01-01            250   \n",
       "pqejgvqb_s001_t013_10      1       120.0     132.0 2015-01-01            250   \n",
       "pqejgvqb_s001_t013_11      1       132.0     144.0 2015-01-01            250   \n",
       "pqejgvqb_s001_t013_12      0       144.0     156.0 2015-01-01            250   \n",
       "\n",
       "                                             signals_path  \n",
       "id                                                         \n",
       "pqejgcff_s001_t000_0   signals/pqejgcff_s001_t000.parquet  \n",
       "pqejgcff_s001_t000_1   signals/pqejgcff_s001_t000.parquet  \n",
       "pqejgcff_s001_t000_2   signals/pqejgcff_s001_t000.parquet  \n",
       "pqejgcff_s001_t000_3   signals/pqejgcff_s001_t000.parquet  \n",
       "pqejgcff_s001_t000_4   signals/pqejgcff_s001_t000.parquet  \n",
       "...                                                   ...  \n",
       "pqejgvqb_s001_t013_8   signals/pqejgvqb_s001_t013.parquet  \n",
       "pqejgvqb_s001_t013_9   signals/pqejgvqb_s001_t013.parquet  \n",
       "pqejgvqb_s001_t013_10  signals/pqejgvqb_s001_t013.parquet  \n",
       "pqejgvqb_s001_t013_11  signals/pqejgvqb_s001_t013.parquet  \n",
       "pqejgvqb_s001_t013_12  signals/pqejgvqb_s001_t013.parquet  \n",
       "\n",
       "[12993 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data'\n",
    "\n",
    "distances = pd.read_csv(f'{data_path}/distances_3d.csv')\n",
    "\n",
    "train_segments = pq.read_table(f'{data_path}/train/segments.parquet').to_pandas()\n",
    "\n",
    "train_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634eb36",
   "metadata": {},
   "source": [
    "We take a look at what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1abc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>FZ</th>\n",
       "      <th>CZ</th>\n",
       "      <th>PZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>59.718113</td>\n",
       "      <td>42.933436</td>\n",
       "      <td>14.857250</td>\n",
       "      <td>7.533027</td>\n",
       "      <td>-39.158892</td>\n",
       "      <td>-11.998233</td>\n",
       "      <td>-9.251650</td>\n",
       "      <td>-40.684771</td>\n",
       "      <td>42.933436</td>\n",
       "      <td>-21.458687</td>\n",
       "      <td>33.778158</td>\n",
       "      <td>10.889962</td>\n",
       "      <td>12.415842</td>\n",
       "      <td>11.500314</td>\n",
       "      <td>-28.782910</td>\n",
       "      <td>-25.425974</td>\n",
       "      <td>19.434889</td>\n",
       "      <td>-44.041707</td>\n",
       "      <td>-35.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>59.942979</td>\n",
       "      <td>44.684182</td>\n",
       "      <td>10.199301</td>\n",
       "      <td>6.537190</td>\n",
       "      <td>-39.544377</td>\n",
       "      <td>-12.994070</td>\n",
       "      <td>-6.585376</td>\n",
       "      <td>-40.154729</td>\n",
       "      <td>43.768654</td>\n",
       "      <td>-20.623469</td>\n",
       "      <td>33.087497</td>\n",
       "      <td>12.640709</td>\n",
       "      <td>14.471764</td>\n",
       "      <td>14.471764</td>\n",
       "      <td>-26.726988</td>\n",
       "      <td>-24.285580</td>\n",
       "      <td>15.082116</td>\n",
       "      <td>-48.089303</td>\n",
       "      <td>-35.882266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>63.075048</td>\n",
       "      <td>45.374844</td>\n",
       "      <td>7.533027</td>\n",
       "      <td>7.533027</td>\n",
       "      <td>-45.872762</td>\n",
       "      <td>-11.387881</td>\n",
       "      <td>-9.556825</td>\n",
       "      <td>-39.158892</td>\n",
       "      <td>44.459316</td>\n",
       "      <td>-15.355168</td>\n",
       "      <td>35.304038</td>\n",
       "      <td>15.162426</td>\n",
       "      <td>7.533027</td>\n",
       "      <td>22.791824</td>\n",
       "      <td>-32.750197</td>\n",
       "      <td>-19.932807</td>\n",
       "      <td>14.552074</td>\n",
       "      <td>-50.450401</td>\n",
       "      <td>-38.853716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>63.026862</td>\n",
       "      <td>45.326658</td>\n",
       "      <td>11.146953</td>\n",
       "      <td>9.315897</td>\n",
       "      <td>-48.667531</td>\n",
       "      <td>-10.825715</td>\n",
       "      <td>-13.267122</td>\n",
       "      <td>-39.512253</td>\n",
       "      <td>45.021482</td>\n",
       "      <td>-14.487826</td>\n",
       "      <td>34.645500</td>\n",
       "      <td>17.555647</td>\n",
       "      <td>8.095193</td>\n",
       "      <td>25.795398</td>\n",
       "      <td>-34.629438</td>\n",
       "      <td>-19.370641</td>\n",
       "      <td>13.283184</td>\n",
       "      <td>-52.939995</td>\n",
       "      <td>-39.512253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12004</th>\n",
       "      <td>61.227931</td>\n",
       "      <td>45.969134</td>\n",
       "      <td>7.211789</td>\n",
       "      <td>6.906613</td>\n",
       "      <td>-48.025056</td>\n",
       "      <td>-12.014295</td>\n",
       "      <td>-14.150526</td>\n",
       "      <td>-40.395657</td>\n",
       "      <td>47.495013</td>\n",
       "      <td>-15.371230</td>\n",
       "      <td>34.372448</td>\n",
       "      <td>17.282595</td>\n",
       "      <td>13.925660</td>\n",
       "      <td>27.658577</td>\n",
       "      <td>-26.357564</td>\n",
       "      <td>-20.864397</td>\n",
       "      <td>11.179077</td>\n",
       "      <td>-54.738926</td>\n",
       "      <td>-41.311185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>58.352852</td>\n",
       "      <td>45.840638</td>\n",
       "      <td>2.505655</td>\n",
       "      <td>5.252239</td>\n",
       "      <td>-48.153551</td>\n",
       "      <td>-13.363494</td>\n",
       "      <td>-12.447966</td>\n",
       "      <td>-42.050032</td>\n",
       "      <td>47.061342</td>\n",
       "      <td>-17.330781</td>\n",
       "      <td>35.769832</td>\n",
       "      <td>18.374804</td>\n",
       "      <td>18.985156</td>\n",
       "      <td>27.530082</td>\n",
       "      <td>-22.823948</td>\n",
       "      <td>-20.077364</td>\n",
       "      <td>11.355757</td>\n",
       "      <td>-53.646718</td>\n",
       "      <td>-41.134504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>59.830546</td>\n",
       "      <td>45.792453</td>\n",
       "      <td>5.204053</td>\n",
       "      <td>7.645460</td>\n",
       "      <td>-48.812088</td>\n",
       "      <td>-10.970272</td>\n",
       "      <td>-14.022031</td>\n",
       "      <td>-42.098218</td>\n",
       "      <td>46.707981</td>\n",
       "      <td>-16.768615</td>\n",
       "      <td>36.942351</td>\n",
       "      <td>18.936970</td>\n",
       "      <td>13.138627</td>\n",
       "      <td>32.059536</td>\n",
       "      <td>-28.670476</td>\n",
       "      <td>-20.430726</td>\n",
       "      <td>11.612748</td>\n",
       "      <td>-53.389727</td>\n",
       "      <td>-42.708570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>60.970940</td>\n",
       "      <td>45.712143</td>\n",
       "      <td>10.922086</td>\n",
       "      <td>10.311734</td>\n",
       "      <td>-48.892398</td>\n",
       "      <td>-9.829878</td>\n",
       "      <td>-16.848924</td>\n",
       "      <td>-40.957823</td>\n",
       "      <td>46.322495</td>\n",
       "      <td>-15.323045</td>\n",
       "      <td>38.082745</td>\n",
       "      <td>18.551485</td>\n",
       "      <td>9.701382</td>\n",
       "      <td>33.505106</td>\n",
       "      <td>-35.464657</td>\n",
       "      <td>-21.426563</td>\n",
       "      <td>13.668670</td>\n",
       "      <td>-54.385565</td>\n",
       "      <td>-44.619935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>58.706214</td>\n",
       "      <td>43.447417</td>\n",
       "      <td>15.981582</td>\n",
       "      <td>8.657360</td>\n",
       "      <td>-45.969134</td>\n",
       "      <td>-10.873901</td>\n",
       "      <td>-16.367067</td>\n",
       "      <td>-42.917374</td>\n",
       "      <td>45.583648</td>\n",
       "      <td>-19.418827</td>\n",
       "      <td>38.259426</td>\n",
       "      <td>14.760878</td>\n",
       "      <td>15.676406</td>\n",
       "      <td>28.798972</td>\n",
       "      <td>-28.879281</td>\n",
       "      <td>-24.911994</td>\n",
       "      <td>15.676406</td>\n",
       "      <td>-53.598532</td>\n",
       "      <td>-42.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>57.421262</td>\n",
       "      <td>43.993521</td>\n",
       "      <td>11.644871</td>\n",
       "      <td>5.846529</td>\n",
       "      <td>-42.676446</td>\n",
       "      <td>-14.600259</td>\n",
       "      <td>-13.684732</td>\n",
       "      <td>-43.897150</td>\n",
       "      <td>45.214225</td>\n",
       "      <td>-21.619306</td>\n",
       "      <td>39.721058</td>\n",
       "      <td>14.086279</td>\n",
       "      <td>20.189798</td>\n",
       "      <td>25.682965</td>\n",
       "      <td>-23.145186</td>\n",
       "      <td>-24.671065</td>\n",
       "      <td>14.391455</td>\n",
       "      <td>-51.221372</td>\n",
       "      <td>-42.676446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12010</th>\n",
       "      <td>60.537269</td>\n",
       "      <td>43.142241</td>\n",
       "      <td>12.319471</td>\n",
       "      <td>8.047008</td>\n",
       "      <td>-41.086319</td>\n",
       "      <td>-12.094604</td>\n",
       "      <td>-12.094604</td>\n",
       "      <td>-43.527726</td>\n",
       "      <td>44.973296</td>\n",
       "      <td>-19.724003</td>\n",
       "      <td>40.395657</td>\n",
       "      <td>12.624647</td>\n",
       "      <td>16.897110</td>\n",
       "      <td>25.136860</td>\n",
       "      <td>-30.405161</td>\n",
       "      <td>-24.606818</td>\n",
       "      <td>15.066054</td>\n",
       "      <td>-50.851949</td>\n",
       "      <td>-44.748430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>60.135722</td>\n",
       "      <td>41.519990</td>\n",
       "      <td>17.716266</td>\n",
       "      <td>9.171340</td>\n",
       "      <td>-42.098218</td>\n",
       "      <td>-9.749568</td>\n",
       "      <td>-14.632383</td>\n",
       "      <td>-41.793042</td>\n",
       "      <td>44.876925</td>\n",
       "      <td>-15.547911</td>\n",
       "      <td>42.740693</td>\n",
       "      <td>9.476516</td>\n",
       "      <td>11.307572</td>\n",
       "      <td>26.566369</td>\n",
       "      <td>-35.689523</td>\n",
       "      <td>-23.787661</td>\n",
       "      <td>15.274859</td>\n",
       "      <td>-52.474200</td>\n",
       "      <td>-43.013746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012</th>\n",
       "      <td>59.172008</td>\n",
       "      <td>39.640748</td>\n",
       "      <td>17.973257</td>\n",
       "      <td>7.292099</td>\n",
       "      <td>-38.484292</td>\n",
       "      <td>-14.070217</td>\n",
       "      <td>-11.323634</td>\n",
       "      <td>-43.672283</td>\n",
       "      <td>45.439091</td>\n",
       "      <td>-17.427152</td>\n",
       "      <td>40.556276</td>\n",
       "      <td>6.986923</td>\n",
       "      <td>16.447377</td>\n",
       "      <td>21.025016</td>\n",
       "      <td>-28.108310</td>\n",
       "      <td>-25.972079</td>\n",
       "      <td>16.752553</td>\n",
       "      <td>-52.217209</td>\n",
       "      <td>-40.010172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>57.903119</td>\n",
       "      <td>39.897739</td>\n",
       "      <td>17.619895</td>\n",
       "      <td>4.497330</td>\n",
       "      <td>-34.565191</td>\n",
       "      <td>-15.644282</td>\n",
       "      <td>-4.657949</td>\n",
       "      <td>-44.635997</td>\n",
       "      <td>48.137489</td>\n",
       "      <td>-20.832273</td>\n",
       "      <td>40.813266</td>\n",
       "      <td>2.055922</td>\n",
       "      <td>21.892358</td>\n",
       "      <td>12.431904</td>\n",
       "      <td>-21.137449</td>\n",
       "      <td>-29.377200</td>\n",
       "      <td>14.873312</td>\n",
       "      <td>-49.823988</td>\n",
       "      <td>-39.448006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>59.123823</td>\n",
       "      <td>37.761507</td>\n",
       "      <td>14.262960</td>\n",
       "      <td>4.192154</td>\n",
       "      <td>-33.039311</td>\n",
       "      <td>-17.475338</td>\n",
       "      <td>-0.385485</td>\n",
       "      <td>-44.330821</td>\n",
       "      <td>49.663369</td>\n",
       "      <td>-19.611570</td>\n",
       "      <td>43.254674</td>\n",
       "      <td>-0.385485</td>\n",
       "      <td>20.366478</td>\n",
       "      <td>8.159441</td>\n",
       "      <td>-21.442625</td>\n",
       "      <td>-29.682376</td>\n",
       "      <td>15.178488</td>\n",
       "      <td>-48.908460</td>\n",
       "      <td>-36.701422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FP1        FP2         F3         F4         C3         C4  \\\n",
       "12000  59.718113  42.933436  14.857250   7.533027 -39.158892 -11.998233   \n",
       "12001  59.942979  44.684182  10.199301   6.537190 -39.544377 -12.994070   \n",
       "12002  63.075048  45.374844   7.533027   7.533027 -45.872762 -11.387881   \n",
       "12003  63.026862  45.326658  11.146953   9.315897 -48.667531 -10.825715   \n",
       "12004  61.227931  45.969134   7.211789   6.906613 -48.025056 -12.014295   \n",
       "12005  58.352852  45.840638   2.505655   5.252239 -48.153551 -13.363494   \n",
       "12006  59.830546  45.792453   5.204053   7.645460 -48.812088 -10.970272   \n",
       "12007  60.970940  45.712143  10.922086  10.311734 -48.892398  -9.829878   \n",
       "12008  58.706214  43.447417  15.981582   8.657360 -45.969134 -10.873901   \n",
       "12009  57.421262  43.993521  11.644871   5.846529 -42.676446 -14.600259   \n",
       "12010  60.537269  43.142241  12.319471   8.047008 -41.086319 -12.094604   \n",
       "12011  60.135722  41.519990  17.716266   9.171340 -42.098218  -9.749568   \n",
       "12012  59.172008  39.640748  17.973257   7.292099 -38.484292 -14.070217   \n",
       "12013  57.903119  39.897739  17.619895   4.497330 -34.565191 -15.644282   \n",
       "12014  59.123823  37.761507  14.262960   4.192154 -33.039311 -17.475338   \n",
       "\n",
       "              P3         P4         O1         O2         F7         F8  \\\n",
       "12000  -9.251650 -40.684771  42.933436 -21.458687  33.778158  10.889962   \n",
       "12001  -6.585376 -40.154729  43.768654 -20.623469  33.087497  12.640709   \n",
       "12002  -9.556825 -39.158892  44.459316 -15.355168  35.304038  15.162426   \n",
       "12003 -13.267122 -39.512253  45.021482 -14.487826  34.645500  17.555647   \n",
       "12004 -14.150526 -40.395657  47.495013 -15.371230  34.372448  17.282595   \n",
       "12005 -12.447966 -42.050032  47.061342 -17.330781  35.769832  18.374804   \n",
       "12006 -14.022031 -42.098218  46.707981 -16.768615  36.942351  18.936970   \n",
       "12007 -16.848924 -40.957823  46.322495 -15.323045  38.082745  18.551485   \n",
       "12008 -16.367067 -42.917374  45.583648 -19.418827  38.259426  14.760878   \n",
       "12009 -13.684732 -43.897150  45.214225 -21.619306  39.721058  14.086279   \n",
       "12010 -12.094604 -43.527726  44.973296 -19.724003  40.395657  12.624647   \n",
       "12011 -14.632383 -41.793042  44.876925 -15.547911  42.740693   9.476516   \n",
       "12012 -11.323634 -43.672283  45.439091 -17.427152  40.556276   6.986923   \n",
       "12013  -4.657949 -44.635997  48.137489 -20.832273  40.813266   2.055922   \n",
       "12014  -0.385485 -44.330821  49.663369 -19.611570  43.254674  -0.385485   \n",
       "\n",
       "              T3         T4         T5         T6         FZ         CZ  \\\n",
       "12000  12.415842  11.500314 -28.782910 -25.425974  19.434889 -44.041707   \n",
       "12001  14.471764  14.471764 -26.726988 -24.285580  15.082116 -48.089303   \n",
       "12002   7.533027  22.791824 -32.750197 -19.932807  14.552074 -50.450401   \n",
       "12003   8.095193  25.795398 -34.629438 -19.370641  13.283184 -52.939995   \n",
       "12004  13.925660  27.658577 -26.357564 -20.864397  11.179077 -54.738926   \n",
       "12005  18.985156  27.530082 -22.823948 -20.077364  11.355757 -53.646718   \n",
       "12006  13.138627  32.059536 -28.670476 -20.430726  11.612748 -53.389727   \n",
       "12007   9.701382  33.505106 -35.464657 -21.426563  13.668670 -54.385565   \n",
       "12008  15.676406  28.798972 -28.879281 -24.911994  15.676406 -53.598532   \n",
       "12009  20.189798  25.682965 -23.145186 -24.671065  14.391455 -51.221372   \n",
       "12010  16.897110  25.136860 -30.405161 -24.606818  15.066054 -50.851949   \n",
       "12011  11.307572  26.566369 -35.689523 -23.787661  15.274859 -52.474200   \n",
       "12012  16.447377  21.025016 -28.108310 -25.972079  16.752553 -52.217209   \n",
       "12013  21.892358  12.431904 -21.137449 -29.377200  14.873312 -49.823988   \n",
       "12014  20.366478   8.159441 -21.442625 -29.682376  15.178488 -48.908460   \n",
       "\n",
       "              PZ  \n",
       "12000 -35.191604  \n",
       "12001 -35.882266  \n",
       "12002 -38.853716  \n",
       "12003 -39.512253  \n",
       "12004 -41.311185  \n",
       "12005 -41.134504  \n",
       "12006 -42.708570  \n",
       "12007 -44.619935  \n",
       "12008 -42.612198  \n",
       "12009 -42.676446  \n",
       "12010 -44.748430  \n",
       "12011 -43.013746  \n",
       "12012 -40.010172  \n",
       "12013 -39.448006  \n",
       "12014 -36.701422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.read_parquet(f\"{data_path}/train/{train_segments.iloc[0][\"signals_path\"]}\").iloc[\n",
    "        12000:12015\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720c4b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>date</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>signals_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pqejgcvm_s001_t000_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcvm_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcvm_s001_t000_1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcvm_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcvm_s001_t000_2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcvm_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcvm_s001_t000_3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcvm_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgcvm_s001_t000_4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgcvm_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvej_s001_t000_153</th>\n",
       "      <td>1836.0</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvej_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvej_s001_t000_154</th>\n",
       "      <td>1848.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvej_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvej_s001_t000_155</th>\n",
       "      <td>1860.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvej_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvej_s001_t000_156</th>\n",
       "      <td>1872.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvej_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pqejgvej_s001_t000_157</th>\n",
       "      <td>1884.0</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>250</td>\n",
       "      <td>signals/pqejgvej_s001_t000.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3614 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        start_time  end_time       date  sampling_rate  \\\n",
       "id                                                                       \n",
       "pqejgcvm_s001_t000_0           0.0      12.0 2002-01-01            250   \n",
       "pqejgcvm_s001_t000_1          12.0      24.0 2002-01-01            250   \n",
       "pqejgcvm_s001_t000_2          24.0      36.0 2002-01-01            250   \n",
       "pqejgcvm_s001_t000_3          36.0      48.0 2002-01-01            250   \n",
       "pqejgcvm_s001_t000_4          48.0      60.0 2002-01-01            250   \n",
       "...                            ...       ...        ...            ...   \n",
       "pqejgvej_s001_t000_153      1836.0    1848.0 2015-01-01            250   \n",
       "pqejgvej_s001_t000_154      1848.0    1860.0 2015-01-01            250   \n",
       "pqejgvej_s001_t000_155      1860.0    1872.0 2015-01-01            250   \n",
       "pqejgvej_s001_t000_156      1872.0    1884.0 2015-01-01            250   \n",
       "pqejgvej_s001_t000_157      1884.0    1896.0 2015-01-01            250   \n",
       "\n",
       "                                              signals_path  \n",
       "id                                                          \n",
       "pqejgcvm_s001_t000_0    signals/pqejgcvm_s001_t000.parquet  \n",
       "pqejgcvm_s001_t000_1    signals/pqejgcvm_s001_t000.parquet  \n",
       "pqejgcvm_s001_t000_2    signals/pqejgcvm_s001_t000.parquet  \n",
       "pqejgcvm_s001_t000_3    signals/pqejgcvm_s001_t000.parquet  \n",
       "pqejgcvm_s001_t000_4    signals/pqejgcvm_s001_t000.parquet  \n",
       "...                                                    ...  \n",
       "pqejgvej_s001_t000_153  signals/pqejgvej_s001_t000.parquet  \n",
       "pqejgvej_s001_t000_154  signals/pqejgvej_s001_t000.parquet  \n",
       "pqejgvej_s001_t000_155  signals/pqejgvej_s001_t000.parquet  \n",
       "pqejgvej_s001_t000_156  signals/pqejgvej_s001_t000.parquet  \n",
       "pqejgvej_s001_t000_157  signals/pqejgvej_s001_t000.parquet  \n",
       "\n",
       "[3614 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_segments = pq.read_table(f'{data_path}/test/segments.parquet').to_pandas()\n",
    "test_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb3a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>FZ</th>\n",
       "      <th>CZ</th>\n",
       "      <th>PZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>-215.871822</td>\n",
       "      <td>-70.302899</td>\n",
       "      <td>1085.398383</td>\n",
       "      <td>-195.425034</td>\n",
       "      <td>1085.398383</td>\n",
       "      <td>-144.460652</td>\n",
       "      <td>598.947935</td>\n",
       "      <td>-252.798111</td>\n",
       "      <td>-1450.918848</td>\n",
       "      <td>-555.532643</td>\n",
       "      <td>25.522346</td>\n",
       "      <td>-136.526078</td>\n",
       "      <td>1095.774364</td>\n",
       "      <td>-420.339702</td>\n",
       "      <td>998.423240</td>\n",
       "      <td>-791.433644</td>\n",
       "      <td>-368.154616</td>\n",
       "      <td>-459.402222</td>\n",
       "      <td>171.701621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>-205.576150</td>\n",
       "      <td>-71.603912</td>\n",
       "      <td>1065.176461</td>\n",
       "      <td>-173.227500</td>\n",
       "      <td>1086.538777</td>\n",
       "      <td>-132.944276</td>\n",
       "      <td>589.407172</td>\n",
       "      <td>-244.943846</td>\n",
       "      <td>-1439.402472</td>\n",
       "      <td>-546.762850</td>\n",
       "      <td>8.657360</td>\n",
       "      <td>-150.339305</td>\n",
       "      <td>1095.388879</td>\n",
       "      <td>-414.926844</td>\n",
       "      <td>1004.446449</td>\n",
       "      <td>-787.241490</td>\n",
       "      <td>-370.981509</td>\n",
       "      <td>-485.422486</td>\n",
       "      <td>173.757543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>-231.275176</td>\n",
       "      <td>-30.774584</td>\n",
       "      <td>1073.351964</td>\n",
       "      <td>-154.981191</td>\n",
       "      <td>1093.798752</td>\n",
       "      <td>-125.989477</td>\n",
       "      <td>573.168600</td>\n",
       "      <td>-237.683871</td>\n",
       "      <td>-1449.537526</td>\n",
       "      <td>-582.837858</td>\n",
       "      <td>-6.970861</td>\n",
       "      <td>-123.548070</td>\n",
       "      <td>1095.019456</td>\n",
       "      <td>-394.239128</td>\n",
       "      <td>1016.894415</td>\n",
       "      <td>-812.635340</td>\n",
       "      <td>-360.974950</td>\n",
       "      <td>-515.699152</td>\n",
       "      <td>174.913999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>-258.034288</td>\n",
       "      <td>-49.599121</td>\n",
       "      <td>1082.298437</td>\n",
       "      <td>-143.593310</td>\n",
       "      <td>1098.777938</td>\n",
       "      <td>-119.179235</td>\n",
       "      <td>580.589193</td>\n",
       "      <td>-234.535740</td>\n",
       "      <td>-1457.070553</td>\n",
       "      <td>-585.488070</td>\n",
       "      <td>-11.452129</td>\n",
       "      <td>-110.023957</td>\n",
       "      <td>1116.783319</td>\n",
       "      <td>-426.796582</td>\n",
       "      <td>1025.535713</td>\n",
       "      <td>-843.666915</td>\n",
       "      <td>-352.944005</td>\n",
       "      <td>-489.052474</td>\n",
       "      <td>177.451778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12004</th>\n",
       "      <td>-214.972356</td>\n",
       "      <td>-61.468859</td>\n",
       "      <td>1074.701163</td>\n",
       "      <td>-156.683752</td>\n",
       "      <td>1084.161617</td>\n",
       "      <td>-109.686657</td>\n",
       "      <td>583.978253</td>\n",
       "      <td>-234.503616</td>\n",
       "      <td>-1464.362651</td>\n",
       "      <td>-572.638557</td>\n",
       "      <td>0.787033</td>\n",
       "      <td>-116.095352</td>\n",
       "      <td>1107.660164</td>\n",
       "      <td>-447.211246</td>\n",
       "      <td>1005.731400</td>\n",
       "      <td>-848.212430</td>\n",
       "      <td>-355.963640</td>\n",
       "      <td>-445.380190</td>\n",
       "      <td>170.159679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>-191.232881</td>\n",
       "      <td>-23.386114</td>\n",
       "      <td>1075.247267</td>\n",
       "      <td>-144.540962</td>\n",
       "      <td>1076.467971</td>\n",
       "      <td>-97.543867</td>\n",
       "      <td>558.584402</td>\n",
       "      <td>-234.262688</td>\n",
       "      <td>-1484.873687</td>\n",
       "      <td>-590.403009</td>\n",
       "      <td>-5.685910</td>\n",
       "      <td>-78.012607</td>\n",
       "      <td>1056.936711</td>\n",
       "      <td>-413.095788</td>\n",
       "      <td>960.806290</td>\n",
       "      <td>-826.304010</td>\n",
       "      <td>-343.820850</td>\n",
       "      <td>-457.346300</td>\n",
       "      <td>162.466033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>-198.926527</td>\n",
       "      <td>-37.793631</td>\n",
       "      <td>1086.474529</td>\n",
       "      <td>-77.161327</td>\n",
       "      <td>1089.221113</td>\n",
       "      <td>-82.959670</td>\n",
       "      <td>537.463015</td>\n",
       "      <td>-229.138945</td>\n",
       "      <td>-1507.826130</td>\n",
       "      <td>-630.140129</td>\n",
       "      <td>-10.022620</td>\n",
       "      <td>-75.635447</td>\n",
       "      <td>1063.281158</td>\n",
       "      <td>-403.394406</td>\n",
       "      <td>950.366060</td>\n",
       "      <td>-827.283786</td>\n",
       "      <td>-324.659014</td>\n",
       "      <td>-488.233317</td>\n",
       "      <td>166.369073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>-205.013984</td>\n",
       "      <td>-54.257070</td>\n",
       "      <td>1081.302600</td>\n",
       "      <td>-76.534913</td>\n",
       "      <td>1077.945665</td>\n",
       "      <td>-87.521247</td>\n",
       "      <td>531.070382</td>\n",
       "      <td>-234.310874</td>\n",
       "      <td>-1516.049818</td>\n",
       "      <td>-635.922410</td>\n",
       "      <td>4.641887</td>\n",
       "      <td>-79.586673</td>\n",
       "      <td>1087.711295</td>\n",
       "      <td>-377.438389</td>\n",
       "      <td>963.504688</td>\n",
       "      <td>-813.839982</td>\n",
       "      <td>-332.882702</td>\n",
       "      <td>-487.912079</td>\n",
       "      <td>155.093625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>-210.539274</td>\n",
       "      <td>-1.188580</td>\n",
       "      <td>1052.583938</td>\n",
       "      <td>-157.133485</td>\n",
       "      <td>1053.499466</td>\n",
       "      <td>-110.746742</td>\n",
       "      <td>536.226249</td>\n",
       "      <td>-245.024155</td>\n",
       "      <td>-1504.790432</td>\n",
       "      <td>-594.145430</td>\n",
       "      <td>4.304587</td>\n",
       "      <td>-59.782360</td>\n",
       "      <td>1081.575652</td>\n",
       "      <td>-343.290808</td>\n",
       "      <td>963.167388</td>\n",
       "      <td>-779.692401</td>\n",
       "      <td>-359.159957</td>\n",
       "      <td>-465.971535</td>\n",
       "      <td>140.107880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>-214.683242</td>\n",
       "      <td>-19.065465</td>\n",
       "      <td>1056.984896</td>\n",
       "      <td>-172.568963</td>\n",
       "      <td>1053.017609</td>\n",
       "      <td>-122.214933</td>\n",
       "      <td>540.322031</td>\n",
       "      <td>-258.933753</td>\n",
       "      <td>-1479.332334</td>\n",
       "      <td>-574.180499</td>\n",
       "      <td>-0.144557</td>\n",
       "      <td>-66.062560</td>\n",
       "      <td>1096.352593</td>\n",
       "      <td>-356.284878</td>\n",
       "      <td>993.203125</td>\n",
       "      <td>-776.817322</td>\n",
       "      <td>-358.115934</td>\n",
       "      <td>-476.219022</td>\n",
       "      <td>134.743208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12010</th>\n",
       "      <td>-188.213245</td>\n",
       "      <td>-32.878692</td>\n",
       "      <td>1070.332328</td>\n",
       "      <td>-147.624845</td>\n",
       "      <td>1062.397754</td>\n",
       "      <td>-132.976400</td>\n",
       "      <td>528.339860</td>\n",
       "      <td>-271.221100</td>\n",
       "      <td>-1467.815958</td>\n",
       "      <td>-590.435133</td>\n",
       "      <td>11.982171</td>\n",
       "      <td>-82.622370</td>\n",
       "      <td>1106.343089</td>\n",
       "      <td>-363.689410</td>\n",
       "      <td>1015.705835</td>\n",
       "      <td>-768.963057</td>\n",
       "      <td>-359.722123</td>\n",
       "      <td>-525.127482</td>\n",
       "      <td>136.188778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>-196.629676</td>\n",
       "      <td>-25.120798</td>\n",
       "      <td>1070.765999</td>\n",
       "      <td>-145.054942</td>\n",
       "      <td>1072.597055</td>\n",
       "      <td>-144.139415</td>\n",
       "      <td>535.487402</td>\n",
       "      <td>-274.449541</td>\n",
       "      <td>-1464.330528</td>\n",
       "      <td>-594.884277</td>\n",
       "      <td>14.857250</td>\n",
       "      <td>-91.954329</td>\n",
       "      <td>1128.749428</td>\n",
       "      <td>-382.786999</td>\n",
       "      <td>1020.717145</td>\n",
       "      <td>-780.736424</td>\n",
       "      <td>-358.678100</td>\n",
       "      <td>-524.388635</td>\n",
       "      <td>139.979385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012</th>\n",
       "      <td>-237.732057</td>\n",
       "      <td>-68.664586</td>\n",
       "      <td>1060.181213</td>\n",
       "      <td>-177.002045</td>\n",
       "      <td>1061.401917</td>\n",
       "      <td>-143.127515</td>\n",
       "      <td>556.640913</td>\n",
       "      <td>-264.892715</td>\n",
       "      <td>-1433.716562</td>\n",
       "      <td>-536.499301</td>\n",
       "      <td>-15.258797</td>\n",
       "      <td>-102.539116</td>\n",
       "      <td>1099.548909</td>\n",
       "      <td>-372.009470</td>\n",
       "      <td>1017.761757</td>\n",
       "      <td>-738.830949</td>\n",
       "      <td>-368.957711</td>\n",
       "      <td>-482.788336</td>\n",
       "      <td>146.484451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>-212.804001</td>\n",
       "      <td>-52.586633</td>\n",
       "      <td>1044.215693</td>\n",
       "      <td>-196.629676</td>\n",
       "      <td>1053.981323</td>\n",
       "      <td>-144.444591</td>\n",
       "      <td>557.154894</td>\n",
       "      <td>-263.768383</td>\n",
       "      <td>-1432.592230</td>\n",
       "      <td>-526.524866</td>\n",
       "      <td>3.870916</td>\n",
       "      <td>-102.025135</td>\n",
       "      <td>1069.850472</td>\n",
       "      <td>-368.138554</td>\n",
       "      <td>992.640959</td>\n",
       "      <td>-722.447819</td>\n",
       "      <td>-371.495489</td>\n",
       "      <td>-475.255309</td>\n",
       "      <td>146.998431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>-194.509507</td>\n",
       "      <td>-28.798972</td>\n",
       "      <td>1059.458428</td>\n",
       "      <td>-172.231663</td>\n",
       "      <td>1071.360289</td>\n",
       "      <td>-145.986532</td>\n",
       "      <td>548.288730</td>\n",
       "      <td>-266.836204</td>\n",
       "      <td>-1439.627338</td>\n",
       "      <td>-566.213800</td>\n",
       "      <td>8.737669</td>\n",
       "      <td>-125.844920</td>\n",
       "      <td>1100.657179</td>\n",
       "      <td>-397.451506</td>\n",
       "      <td>1018.259676</td>\n",
       "      <td>-749.624540</td>\n",
       "      <td>-360.525217</td>\n",
       "      <td>-511.282131</td>\n",
       "      <td>152.170360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FP1        FP2           F3          F4           C3  \\\n",
       "12000 -215.871822 -70.302899  1085.398383 -195.425034  1085.398383   \n",
       "12001 -205.576150 -71.603912  1065.176461 -173.227500  1086.538777   \n",
       "12002 -231.275176 -30.774584  1073.351964 -154.981191  1093.798752   \n",
       "12003 -258.034288 -49.599121  1082.298437 -143.593310  1098.777938   \n",
       "12004 -214.972356 -61.468859  1074.701163 -156.683752  1084.161617   \n",
       "12005 -191.232881 -23.386114  1075.247267 -144.540962  1076.467971   \n",
       "12006 -198.926527 -37.793631  1086.474529  -77.161327  1089.221113   \n",
       "12007 -205.013984 -54.257070  1081.302600  -76.534913  1077.945665   \n",
       "12008 -210.539274  -1.188580  1052.583938 -157.133485  1053.499466   \n",
       "12009 -214.683242 -19.065465  1056.984896 -172.568963  1053.017609   \n",
       "12010 -188.213245 -32.878692  1070.332328 -147.624845  1062.397754   \n",
       "12011 -196.629676 -25.120798  1070.765999 -145.054942  1072.597055   \n",
       "12012 -237.732057 -68.664586  1060.181213 -177.002045  1061.401917   \n",
       "12013 -212.804001 -52.586633  1044.215693 -196.629676  1053.981323   \n",
       "12014 -194.509507 -28.798972  1059.458428 -172.231663  1071.360289   \n",
       "\n",
       "               C4          P3          P4           O1          O2         F7  \\\n",
       "12000 -144.460652  598.947935 -252.798111 -1450.918848 -555.532643  25.522346   \n",
       "12001 -132.944276  589.407172 -244.943846 -1439.402472 -546.762850   8.657360   \n",
       "12002 -125.989477  573.168600 -237.683871 -1449.537526 -582.837858  -6.970861   \n",
       "12003 -119.179235  580.589193 -234.535740 -1457.070553 -585.488070 -11.452129   \n",
       "12004 -109.686657  583.978253 -234.503616 -1464.362651 -572.638557   0.787033   \n",
       "12005  -97.543867  558.584402 -234.262688 -1484.873687 -590.403009  -5.685910   \n",
       "12006  -82.959670  537.463015 -229.138945 -1507.826130 -630.140129 -10.022620   \n",
       "12007  -87.521247  531.070382 -234.310874 -1516.049818 -635.922410   4.641887   \n",
       "12008 -110.746742  536.226249 -245.024155 -1504.790432 -594.145430   4.304587   \n",
       "12009 -122.214933  540.322031 -258.933753 -1479.332334 -574.180499  -0.144557   \n",
       "12010 -132.976400  528.339860 -271.221100 -1467.815958 -590.435133  11.982171   \n",
       "12011 -144.139415  535.487402 -274.449541 -1464.330528 -594.884277  14.857250   \n",
       "12012 -143.127515  556.640913 -264.892715 -1433.716562 -536.499301 -15.258797   \n",
       "12013 -144.444591  557.154894 -263.768383 -1432.592230 -526.524866   3.870916   \n",
       "12014 -145.986532  548.288730 -266.836204 -1439.627338 -566.213800   8.737669   \n",
       "\n",
       "               F8           T3          T4           T5          T6  \\\n",
       "12000 -136.526078  1095.774364 -420.339702   998.423240 -791.433644   \n",
       "12001 -150.339305  1095.388879 -414.926844  1004.446449 -787.241490   \n",
       "12002 -123.548070  1095.019456 -394.239128  1016.894415 -812.635340   \n",
       "12003 -110.023957  1116.783319 -426.796582  1025.535713 -843.666915   \n",
       "12004 -116.095352  1107.660164 -447.211246  1005.731400 -848.212430   \n",
       "12005  -78.012607  1056.936711 -413.095788   960.806290 -826.304010   \n",
       "12006  -75.635447  1063.281158 -403.394406   950.366060 -827.283786   \n",
       "12007  -79.586673  1087.711295 -377.438389   963.504688 -813.839982   \n",
       "12008  -59.782360  1081.575652 -343.290808   963.167388 -779.692401   \n",
       "12009  -66.062560  1096.352593 -356.284878   993.203125 -776.817322   \n",
       "12010  -82.622370  1106.343089 -363.689410  1015.705835 -768.963057   \n",
       "12011  -91.954329  1128.749428 -382.786999  1020.717145 -780.736424   \n",
       "12012 -102.539116  1099.548909 -372.009470  1017.761757 -738.830949   \n",
       "12013 -102.025135  1069.850472 -368.138554   992.640959 -722.447819   \n",
       "12014 -125.844920  1100.657179 -397.451506  1018.259676 -749.624540   \n",
       "\n",
       "               FZ          CZ          PZ  \n",
       "12000 -368.154616 -459.402222  171.701621  \n",
       "12001 -370.981509 -485.422486  173.757543  \n",
       "12002 -360.974950 -515.699152  174.913999  \n",
       "12003 -352.944005 -489.052474  177.451778  \n",
       "12004 -355.963640 -445.380190  170.159679  \n",
       "12005 -343.820850 -457.346300  162.466033  \n",
       "12006 -324.659014 -488.233317  166.369073  \n",
       "12007 -332.882702 -487.912079  155.093625  \n",
       "12008 -359.159957 -465.971535  140.107880  \n",
       "12009 -358.115934 -476.219022  134.743208  \n",
       "12010 -359.722123 -525.127482  136.188778  \n",
       "12011 -358.678100 -524.388635  139.979385  \n",
       "12012 -368.957711 -482.788336  146.484451  \n",
       "12013 -371.495489 -475.255309  146.998431  \n",
       "12014 -360.525217 -511.282131  152.170360  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.read_parquet(f\"{data_path}/test/{test_segments.iloc[0]['signals_path']}\")\n",
    "    .iloc[12000:12015]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc249ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FP1</td>\n",
       "      <td>FP1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FP1</td>\n",
       "      <td>FP2</td>\n",
       "      <td>0.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP1</td>\n",
       "      <td>F3</td>\n",
       "      <td>0.618969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FP1</td>\n",
       "      <td>F4</td>\n",
       "      <td>1.030322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FP1</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.250226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>PZ</td>\n",
       "      <td>T5</td>\n",
       "      <td>1.081066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>PZ</td>\n",
       "      <td>T6</td>\n",
       "      <td>1.081066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>PZ</td>\n",
       "      <td>FZ</td>\n",
       "      <td>1.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>PZ</td>\n",
       "      <td>CZ</td>\n",
       "      <td>0.765363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>PZ</td>\n",
       "      <td>PZ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    from   to  distance\n",
       "0    FP1  FP1  0.000000\n",
       "1    FP1  FP2  0.618000\n",
       "2    FP1   F3  0.618969\n",
       "3    FP1   F4  1.030322\n",
       "4    FP1   C3  1.250226\n",
       "..   ...  ...       ...\n",
       "356   PZ   T5  1.081066\n",
       "357   PZ   T6  1.081066\n",
       "358   PZ   FZ  1.414200\n",
       "359   PZ   CZ  0.765363\n",
       "360   PZ   PZ  0.000000\n",
       "\n",
       "[361 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1520a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_index(distances_df, threshold=1):\n",
    "    \"\"\"Create edge index based on electrode distances.\"\"\"\n",
    "\n",
    "    unique_electrodes = set()\n",
    "    for idx, row in distances_df.iterrows():\n",
    "        unique_electrodes.add(row['from'])\n",
    "        unique_electrodes.add(row['to'])\n",
    "    \n",
    "    electrode_to_idx = {electrode: idx for idx, electrode in enumerate(unique_electrodes)}\n",
    "    \n",
    "    edge_index = []\n",
    "    \n",
    "    for idx, row in distances_df.iterrows():\n",
    "        source_name = row['from']\n",
    "        target_name = row['to']\n",
    "        distance = row['distance']\n",
    "        \n",
    "        source_idx = electrode_to_idx[source_name]\n",
    "        target_idx = electrode_to_idx[target_name]\n",
    "        \n",
    "        if distance < threshold:\n",
    "            edge_index.append([source_idx, target_idx])\n",
    "            edge_index.append([target_idx, source_idx])\n",
    "    \n",
    "    if not edge_index:  \n",
    "        print(\"Warning: No edges were created with the current threshold. Try increasing the threshold.\")\n",
    "        # Create a fallback edge_index with at least one edge\n",
    "        if len(electrode_to_idx) > 1:\n",
    "            edge_index = [[0, 1], [1, 0]]\n",
    "    \n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c44efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_index_and_attr(distances_df, connection_threshold=1, use_all_connections=True):\n",
    "    \"\"\"\n",
    "    Create edge index and edge attributes based on electrode distances.\n",
    "    \n",
    "    Args:\n",
    "        distances_df: DataFrame with electrode distances\n",
    "        connection_threshold: Threshold for creating edges\n",
    "        use_all_connections: If True, use all connections with distance-based weights\n",
    "                            If False, only use connections below threshold\n",
    "    \"\"\"\n",
    "    # First, create a mapping from electrode names to indices\n",
    "    unique_electrodes = set()\n",
    "    for idx, row in distances_df.iterrows():\n",
    "        unique_electrodes.add(row['from'])\n",
    "        unique_electrodes.add(row['to'])\n",
    "    \n",
    "    electrode_to_idx = {electrode: idx for idx, electrode in enumerate(sorted(unique_electrodes))}\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "\n",
    "    all_distances = distances_df['distance'].values\n",
    "    max_distance = np.max(all_distances)\n",
    "    min_distance = np.min(all_distances)\n",
    "    \n",
    "\n",
    "    for idx, row in distances_df.iterrows():\n",
    "        source_name = row['from']\n",
    "        target_name = row['to']\n",
    "        distance = row['distance']\n",
    "        \n",
    "        source_idx = electrode_to_idx[source_name]\n",
    "        target_idx = electrode_to_idx[target_name]\n",
    "        \n",
    "        norm_distance = (distance - min_distance) / (max_distance - min_distance)\n",
    "        \n",
    "        inverse_dist = 1.0 / (norm_distance + 0.001)  # Avoid division by zero\n",
    "        gaussian_weight = np.exp(-norm_distance**2)\n",
    "        \n",
    "        edge_features = [norm_distance, inverse_dist, gaussian_weight]\n",
    "        \n",
    "        if use_all_connections or distance < connection_threshold:\n",
    "            edge_index.append([source_idx, target_idx])\n",
    "            edge_attr.append(edge_features)\n",
    "            \n",
    "            edge_index.append([target_idx, source_idx])\n",
    "            edge_attr.append(edge_features)\n",
    "    \n",
    "    if not edge_index:  # Check if edge_index is empty\n",
    "        print(\"Warning: No edges were created. Using fallback edges.\")\n",
    "        if len(electrode_to_idx) > 1:\n",
    "            edge_index = [[0, 1], [1, 0]]\n",
    "            edge_attr = [[0.5, 2.0, 0.6], [0.5, 2.0, 0.6]]\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "        torch.tensor(edge_attr, dtype=torch.float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8195b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_features(eeg_data, sampling_rate=250):\n",
    "    \"\"\"Extract meaningful features from EEG data for each electrode.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for column in eeg_data.columns:\n",
    "        signal = eeg_data[column].values\n",
    "        \n",
    "        mean = np.mean(signal)\n",
    "        std = np.std(signal)\n",
    "        min_val = np.min(signal)\n",
    "        max_val = np.max(signal)\n",
    "        \n",
    "        signal_fft = np.abs(np.fft.rfft(signal))\n",
    "        freq = np.fft.rfftfreq(len(signal), d=1/sampling_rate)\n",
    "        \n",
    "        # Extract power in standard EEG frequency bands\n",
    "        # Delta: 0.5-4 Hz (deep sleep)\n",
    "        delta_idx = np.logical_and(freq >= 0.5, freq < 4)\n",
    "        delta_power = np.sum(signal_fft[delta_idx]**2)\n",
    "        \n",
    "        # Theta: 4-8 Hz (drowsiness)\n",
    "        theta_idx = np.logical_and(freq >= 4, freq < 8)\n",
    "        theta_power = np.sum(signal_fft[theta_idx]**2)\n",
    "        \n",
    "        # Alpha: 8-13 Hz (relaxed wakefulness)\n",
    "        alpha_idx = np.logical_and(freq >= 8, freq < 13)\n",
    "        alpha_power = np.sum(signal_fft[alpha_idx]**2)\n",
    "        \n",
    "        # Beta: 13-30 Hz (active thinking)\n",
    "        beta_idx = np.logical_and(freq >= 13, freq < 30)\n",
    "        beta_power = np.sum(signal_fft[beta_idx]**2)\n",
    "        \n",
    "        # Gamma: 30+ Hz (cognitive processing)\n",
    "        gamma_idx = freq >= 30\n",
    "        gamma_power = np.sum(signal_fft[gamma_idx]**2)\n",
    "        \n",
    "        # Dominant frequency (frequency with maximum power)\n",
    "        dom_freq = freq[np.argmax(signal_fft)]\n",
    "        \n",
    "        # Spectral edge frequency (95% of power is below this frequency)\n",
    "        total_power = np.sum(signal_fft**2)\n",
    "        cumulative_power = np.cumsum(signal_fft**2)\n",
    "        spectral_edge_idx = np.where(cumulative_power >= 0.95 * total_power)[0]\n",
    "        spectral_edge = freq[spectral_edge_idx[0]] if len(spectral_edge_idx) > 0 else freq[-1]\n",
    "        \n",
    "        # Band power ratios \n",
    "        total_band_power = delta_power + theta_power + alpha_power + beta_power + gamma_power\n",
    "        if total_band_power > 0:\n",
    "            delta_ratio = delta_power / total_band_power\n",
    "            theta_ratio = theta_power / total_band_power\n",
    "            alpha_ratio = alpha_power / total_band_power\n",
    "            beta_ratio = beta_power / total_band_power\n",
    "            gamma_ratio = gamma_power / total_band_power\n",
    "        else:\n",
    "            delta_ratio = theta_ratio = alpha_ratio = beta_ratio = gamma_ratio = 0\n",
    "        \n",
    "        # Combining all features\n",
    "        node_feature = [\n",
    "            mean, std, min_val, max_val,\n",
    "            delta_power, theta_power, alpha_power, beta_power, gamma_power,\n",
    "            dom_freq, spectral_edge,\n",
    "            delta_ratio, theta_ratio, alpha_ratio, beta_ratio, gamma_ratio\n",
    "        ]\n",
    "        features.append(node_feature)\n",
    "    \n",
    "    return torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89658fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class EnhancedGATWithEdgeFeatures(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, edge_dim=3, num_heads=8, dropout=0.3):\n",
    "        super(EnhancedGATWithEdgeFeatures, self).__init__()\n",
    "        \n",
    "        # Define attention layers with edge features\n",
    "        self.gat1 = pyg_nn.GATv2Conv(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            concat=True,\n",
    "            edge_dim=edge_dim  # Include edge features\n",
    "        )\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "        \n",
    "        self.gat2 = pyg_nn.GATv2Conv(\n",
    "            in_channels=hidden_dim * num_heads,\n",
    "            out_channels=hidden_dim, \n",
    "            heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            concat=True,\n",
    "            edge_dim=edge_dim  # Include edge features\n",
    "        )\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "        \n",
    "        self.gat3 = pyg_nn.GATv2Conv(\n",
    "            in_channels=hidden_dim * num_heads, \n",
    "            out_channels=hidden_dim,\n",
    "            heads=1, \n",
    "            dropout=dropout,\n",
    "            concat=False,\n",
    "            edge_dim=edge_dim  # Include edge features\n",
    "        )\n",
    "        \n",
    "        # Graph-level readout\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # First GAT layer\n",
    "        x = self.gat1(x, edge_index, edge_attr)\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        x = self.bn2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final GAT layer\n",
    "        x = self.gat3(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Global pooling (graph-level prediction)\n",
    "        x = torch.mean(x, dim=0)\n",
    "        \n",
    "        # Ensure correct shape for the linear layer\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = self.linear(x)  # Final prediction\n",
    "        \n",
    "        # For binary classification (epilepsy detection)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5604b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gat_model(model, train_data_list, val_data_list, epochs=100, lr=0.001):\n",
    "    \"\"\"Train the GAT model for epilepsy detection.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on: {device}\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        # Add this at the beginning of your training loop\n",
    "        print(f\"Sample data dimensions:\")\n",
    "        for i, data in enumerate([train_data_list[0]]):\n",
    "            print(f\"  x shape: {data.x.shape}\")\n",
    "            print(f\"  edge_index shape: {data.edge_index.shape}\")\n",
    "            print(f\"  y shape: {data.y.shape}\")\n",
    "            print(f\"  Model output shape: {model(data.x, data.edge_index).shape}\")\n",
    "            break\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Process each graph separately (batch size = 1 for graph data)\n",
    "        for i, data in enumerate(train_data_list):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move data to device\n",
    "            x = data.x.to(device)\n",
    "            edge_index = data.edge_index.to(device)\n",
    "            y = data.y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(x, edge_index)\n",
    "            \n",
    "            # Handle dimension matching\n",
    "            if out.shape != y.shape:\n",
    "                if out.dim() > y.dim():\n",
    "                    y = y.unsqueeze(-1)\n",
    "                elif y.dim() > out.dim():\n",
    "                    out = out.unsqueeze(-1)\n",
    "            \n",
    "            loss = loss_fn(out, y)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print mini-batch progress occasionally\n",
    "            if (i+1) % 500 == 0:\n",
    "                tqdm.write(f'  Batch {i+1}/{len(train_data_list)}, Loss: {loss.item():.4f}')\n",
    "            \n",
    "        \n",
    "        # Calculate average epoch loss\n",
    "        avg_epoch_loss = epoch_loss / len(train_data_list)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in val_data_list:\n",
    "                val_x = val_data.x.to(device)\n",
    "                val_edge_index = val_data.edge_index.to(device)\n",
    "                val_y = val_data.y.to(device)\n",
    "                \n",
    "                val_out = model(val_x, val_edge_index)\n",
    "                \n",
    "                # Handle dimension matching\n",
    "                if val_out.shape != val_y.shape:\n",
    "                    if val_out.dim() > val_y.dim():\n",
    "                        val_y = val_y.unsqueeze(-1)\n",
    "                    elif val_y.dim() > val_out.dim():\n",
    "                        val_out = val_out.unsqueeze(-1)\n",
    "                \n",
    "                val_loss += loss_fn(val_out, val_y).item()\n",
    "                \n",
    "                # Calculate validation accuracy\n",
    "                val_preds = (val_out > 0.5).float()\n",
    "                correct += (val_preds == val_y).sum().item()\n",
    "                total += val_y.numel()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_data_list)\n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        # Print progress each epoch\n",
    "        tqdm.write(f'Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4561f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_gat_model_with_edge_attr(model, train_data_list, val_data_list, epochs=100, lr=0.001):\n",
    "    \"\"\"Train the GAT model with edge attributes.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on: {device}\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        # Debug information\n",
    "        print(f\"Sample data dimensions:\")\n",
    "        for i, data in enumerate([train_data_list[0]]):\n",
    "            print(f\"  x shape: {data.x.shape}\")\n",
    "            print(f\"  edge_index shape: {data.edge_index.shape}\")\n",
    "            print(f\"  edge_attr shape: {data.edge_attr.shape}\")\n",
    "            print(f\"  y shape: {data.y.shape}\")\n",
    "            print(f\"  Model output shape: {model(data.x, data.edge_index, data.edge_attr).shape}\")\n",
    "            break\n",
    "            \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Process each graph separately\n",
    "        for i, data in enumerate(train_data_list):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move data to device\n",
    "            x = data.x.to(device)\n",
    "            edge_index = data.edge_index.to(device)\n",
    "            edge_attr = data.edge_attr.to(device)\n",
    "            y = data.y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(x, edge_index, edge_attr)\n",
    "            \n",
    "            # Handle dimension matching\n",
    "            if out.shape != y.shape:\n",
    "                if out.dim() > y.dim():\n",
    "                    y = y.unsqueeze(-1)\n",
    "                elif y.dim() > out.dim():\n",
    "                    out = out.unsqueeze(-1)\n",
    "            \n",
    "            loss = loss_fn(out, y)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print mini-batch progress occasionally\n",
    "            if (i+1) % 100 == 0:\n",
    "                tqdm.write(f'  Batch {i+1}/{len(train_data_list)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Calculate average epoch loss\n",
    "        avg_epoch_loss = epoch_loss / len(train_data_list)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in val_data_list:\n",
    "                val_x = val_data.x.to(device)\n",
    "                val_edge_index = val_data.edge_index.to(device)\n",
    "                val_edge_attr = val_data.edge_attr.to(device)\n",
    "                val_y = val_data.y.to(device)\n",
    "                \n",
    "                val_out = model(val_x, val_edge_index, val_edge_attr)\n",
    "                \n",
    "                # Handle dimension matching\n",
    "                if val_out.shape != val_y.shape:\n",
    "                    if val_out.dim() > val_y.dim():\n",
    "                        val_y = val_y.unsqueeze(-1)\n",
    "                    elif val_y.dim() > val_out.dim():\n",
    "                        val_out = val_out.unsqueeze(-1)\n",
    "                \n",
    "                val_loss += loss_fn(val_out, val_y).item()\n",
    "                \n",
    "                # Calculate validation accuracy\n",
    "                val_preds = (val_out > 0.5).float()\n",
    "                correct += (val_preds == val_y).sum().item()\n",
    "                total += val_y.numel()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_data_list)\n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        # Print progress each epoch\n",
    "        tqdm.write(f'Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bcf92c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first segment:\n",
      "label                                             1\n",
      "start_time                                      0.0\n",
      "end_time                                       12.0\n",
      "date                            2003-01-01 00:00:00\n",
      "sampling_rate                                   250\n",
      "signals_path     signals/pqejgcff_s001_t000.parquet\n",
      "Name: pqejgcff_s001_t000_0, dtype: object\n",
      "Full expected path: ../data/train/signals/pqejgcff_s001_t000.parquet\n",
      "Directory ../data/train exists: True\n",
      "Contents: ['segments.parquet', 'signals']\n"
     ]
    }
   ],
   "source": [
    "# Check what's inside a segment to debug the path issue\n",
    "print(\"Checking first segment:\")\n",
    "print(train_segments.iloc[0])\n",
    "print(\"Full expected path:\", f\"{data_path}/train/{train_segments.iloc[0]['signals_path']}\")\n",
    "\n",
    "# Check if directory exists\n",
    "import os\n",
    "path_to_check = f\"{data_path}/train\"\n",
    "print(f\"Directory {path_to_check} exists:\", os.path.exists(path_to_check))\n",
    "\n",
    "# List directory contents\n",
    "if os.path.exists(path_to_check):\n",
    "    print(\"Contents:\", os.listdir(path_to_check)[:10])  # Show first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fea3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eeg_data(segments_df, data_path, distances_df, threshold=0.1):\n",
    "    \"\"\"Process EEG segments and prepare them for GAT model.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Create electrode mapping once\n",
    "    edge_index = create_edge_index(distances_df, threshold)\n",
    "    print(f\"Created edge_index with shape {edge_index.shape}\")\n",
    "    \n",
    "    for idx, segment in segments_df.iterrows():\n",
    "        try:\n",
    "            # Load EEG data for this segment\n",
    "            eeg_data = pd.read_parquet(f\"{data_path}/{segment['signals_path']}\")\n",
    "            \n",
    "            # Create node features from EEG data\n",
    "            node_features = extract_eeg_features(eeg_data)\n",
    "            \n",
    "            # Create label (1 for seizure, 0 for non-seizure)\n",
    "            if 'seizure' in segment.index:\n",
    "                label = torch.tensor([[1.0 if segment['seizure'] else 0.0]]).float()  # Shape: [1, 1]\n",
    "            else:\n",
    "                label = torch.tensor([[0.0]]).float()  # Shape: [1, 1] \n",
    "            \n",
    "            # Create PyTorch Geometric Data object\n",
    "            data = Data(\n",
    "                x=node_features,\n",
    "                edge_index=edge_index,\n",
    "                y=label\n",
    "            )\n",
    "            \n",
    "            all_data.append(data)\n",
    "            \n",
    "            # Print shapes for debug\n",
    "            if idx == 0:\n",
    "                print(f\"Sample data shapes - x: {data.x.shape}, edge_index: {data.edge_index.shape}, y: {data.y.shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09baaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eeg_data_with_edge_features(segments_df, data_path, distances_df, threshold=0.3):\n",
    "    \"\"\"Process EEG segments and prepare them for GAT model with edge features.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Create electrode mapping and edge attributes once\n",
    "    edge_index, edge_attr = create_edge_index_and_attr(distances_df, threshold)\n",
    "    print(f\"Created edge_index with shape {edge_index.shape}\")\n",
    "    print(f\"Created edge_attr with shape {edge_attr.shape}\")\n",
    "\n",
    "    counter = 0\n",
    "    for idx, segment in tqdm(segments_df.iterrows(), total=len(segments_df), desc=\"Processing EEG segments\"):\n",
    "        try:\n",
    "            # Load EEG data for this segment\n",
    "            eeg_data = pd.read_parquet(f\"{data_path}/{segment['signals_path']}\")\n",
    "            \n",
    "            # Create node features from EEG data\n",
    "            node_features = extract_eeg_features(eeg_data)\n",
    "            \n",
    "            # Create label (1 for seizure, 0 for non-seizure)\n",
    "            if 'seizure' in segment.index:\n",
    "                label = torch.tensor([[1.0 if segment['seizure'] else 0.0]]).float()\n",
    "            else:\n",
    "                label = torch.tensor([[0.0]]).float()\n",
    "            \n",
    "            # Create PyTorch Geometric Data object with edge attributes\n",
    "            data = Data(\n",
    "                x=node_features,\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_attr,\n",
    "                y=label\n",
    "            )\n",
    "            \n",
    "            all_data.append(data)\n",
    "            \n",
    "            # Print shapes for the first few samples\n",
    "            if counter < 3:  \n",
    "                print(f\"Sample {idx} shapes - x: {data.x.shape}, edge_index: {data.edge_index.shape}, edge_attr: {data.edge_attr.shape}\")\n",
    "                \n",
    "            counter += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92de7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_features_optimized(eeg_data, sampling_rate=256):\n",
    "    \"\"\"Extract meaningful features from EEG data for each electrode - optimized version.\"\"\"\n",
    "    # Preallocate output array for better performance\n",
    "    features = np.zeros((len(eeg_data.columns), 16), dtype=np.float32)\n",
    "    \n",
    "    # Extract all signals at once as a numpy array\n",
    "    all_signals = eeg_data.values.T  # Transpose to get electrode x timepoints\n",
    "    \n",
    "    # Calculate FFTs in batch (much faster than one-by-one)\n",
    "    all_ffts = np.abs(np.fft.rfft(all_signals, axis=1))\n",
    "    freq = np.fft.rfftfreq(all_signals.shape[1], d=1/sampling_rate)\n",
    "    \n",
    "    # Prepare frequency band indices once\n",
    "    delta_idx = np.logical_and(freq >= 0.5, freq < 4)\n",
    "    theta_idx = np.logical_and(freq >= 4, freq < 8)\n",
    "    alpha_idx = np.logical_and(freq >= 8, freq < 13)\n",
    "    beta_idx = np.logical_and(freq >= 13, freq < 30)\n",
    "    gamma_idx = freq >= 30\n",
    "    \n",
    "    # Process each electrode\n",
    "    for i, column in enumerate(eeg_data.columns):\n",
    "        signal = all_signals[i]\n",
    "        signal_fft = all_ffts[i]\n",
    "        \n",
    "        # Basic statistical features\n",
    "        features[i, 0] = np.mean(signal)\n",
    "        features[i, 1] = np.std(signal)\n",
    "        features[i, 2] = np.min(signal)\n",
    "        features[i, 3] = np.max(signal)\n",
    "        \n",
    "        # Power in frequency bands\n",
    "        features[i, 4] = np.sum(signal_fft[delta_idx]**2)  # Delta\n",
    "        features[i, 5] = np.sum(signal_fft[theta_idx]**2)  # Theta\n",
    "        features[i, 6] = np.sum(signal_fft[alpha_idx]**2)  # Alpha\n",
    "        features[i, 7] = np.sum(signal_fft[beta_idx]**2)   # Beta\n",
    "        features[i, 8] = np.sum(signal_fft[gamma_idx]**2)  # Gamma\n",
    "        \n",
    "        # Dominant frequency\n",
    "        features[i, 9] = freq[np.argmax(signal_fft)]\n",
    "        \n",
    "        # Spectral edge\n",
    "        total_power = np.sum(signal_fft**2)\n",
    "        if total_power > 0:\n",
    "            cumulative_power = np.cumsum(signal_fft**2)\n",
    "            spectral_edge_idx = np.where(cumulative_power >= 0.95 * total_power)[0]\n",
    "            features[i, 10] = freq[spectral_edge_idx[0]] if len(spectral_edge_idx) > 0 else freq[-1]\n",
    "        else:\n",
    "            features[i, 10] = 0\n",
    "        \n",
    "        # Band power ratios\n",
    "        band_total = features[i, 4] + features[i, 5] + features[i, 6] + features[i, 7] + features[i, 8]\n",
    "        if band_total > 0:\n",
    "            features[i, 11] = features[i, 4] / band_total  # Delta ratio\n",
    "            features[i, 12] = features[i, 5] / band_total  # Theta ratio\n",
    "            features[i, 13] = features[i, 6] / band_total  # Alpha ratio\n",
    "            features[i, 14] = features[i, 7] / band_total  # Beta ratio\n",
    "            features[i, 15] = features[i, 8] / band_total  # Gamma ratio\n",
    "    \n",
    "    return torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3efd1d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and print info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Usage:\")\n",
    "    print(f\"Allocated: {round(torch.cuda.memory_allocated(0)/1024**3, 1)} GB\")\n",
    "    print(f\"Cached: {round(torch.cuda.memory_reserved(0)/1024**3, 1)} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8796513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 5 segments\n",
      "Created edge_index with shape torch.Size([2, 722])\n",
      "Created edge_attr with shape torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_0 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_1 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:01,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_2 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 segments in 2.54 seconds (0.51 seconds per segment)\n",
      "\n",
      "First sample details:\n",
      "Node features shape: torch.Size([19, 16])\n",
      "Edge index shape: torch.Size([2, 722])\n",
      "Edge attr shape: torch.Size([722, 3])\n",
      "Label: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with just a few samples first\n",
    "sample_size = 5  # Start with just 5 segments\n",
    "sample_segments = train_segments.iloc[:sample_size]\n",
    "print(f\"Testing with {len(sample_segments)} segments\")\n",
    "\n",
    "# Replace the extract_eeg_features function with the optimized version\n",
    "# This is just for the cell that runs this test\n",
    "import time\n",
    "start_time = time.time()\n",
    "sample_data = prepare_eeg_data_with_edge_features(sample_segments, f'{data_path}/train', distances, threshold=0.3)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Processed {len(sample_data)} segments in {elapsed:.2f} seconds ({elapsed/len(sample_data):.2f} seconds per segment)\")\n",
    "\n",
    "# Examine one processed sample\n",
    "if len(sample_data) > 0:\n",
    "    print(\"\\nFirst sample details:\")\n",
    "    print(f\"Node features shape: {sample_data[0].x.shape}\")\n",
    "    print(f\"Edge index shape: {sample_data[0].edge_index.shape}\")\n",
    "    print(f\"Edge attr shape: {sample_data[0].edge_attr.shape}\")\n",
    "    print(f\"Label: {sample_data[0].y.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0edaf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n",
      "Created edge_index with shape torch.Size([2, 722])\n",
      "Created edge_attr with shape torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:   0%|          | 0/12993 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:   0%|          | 1/12993 [00:00<1:27:59,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_0 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:   0%|          | 2/12993 [00:00<1:26:53,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_1 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:   0%|          | 3/12993 [00:01<1:26:07,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pqejgcff_s001_t000_2 shapes - x: torch.Size([19, 16]), edge_index: torch.Size([2, 722]), edge_attr: torch.Size([722, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG segments:  20%|â–ˆâ–ˆ        | 2633/12993 [26:44<5:14:09,  1.82s/it]"
     ]
    }
   ],
   "source": [
    "# First, import tqdm if not already imported\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "input_dim = 16  # Number of features per node (from extract_eeg_features)\n",
    "hidden_dim = 32\n",
    "output_dim = 1  # Binary classification\n",
    "edge_dim = 3    # We're using 3 edge features now\n",
    "num_heads = 8\n",
    "threshold = 0.3  # Threshold for edge feature calculations\n",
    "\n",
    "# Prepare data with edge features\n",
    "print(\"Preparing training data...\")\n",
    "train_data = prepare_eeg_data_with_edge_features(train_segments, f'{data_path}/train', distances, threshold)\n",
    "print(f\"Created {len(train_data)} training samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, val_samples = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training on {len(train_samples)} samples, validating on {len(val_samples)} samples\")\n",
    "\n",
    "# Initialize model with edge features\n",
    "model = EnhancedGATWithEdgeFeatures(input_dim, hidden_dim, output_dim, edge_dim, num_heads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "trained_model = train_gat_model_with_edge_attr(model, train_samples, val_samples, epochs=10, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28769b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test data\n",
    "print(\"Processing test data...\")\n",
    "test_data = prepare_eeg_data_with_edge_features(test_segments, f'{data_path}/test', distances, threshold)\n",
    "\n",
    "# Make predictions on test data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for data in test_data:\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    edge_attr = data.edge_attr.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(x, edge_index, edge_attr)\n",
    "        pred = (out > 0.5).float().cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "\n",
    "# Save predictions\n",
    "test_segments['prediction'] = predictions\n",
    "test_segments.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, val_samples = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training on {len(train_samples)} samples, validating on {len(val_samples)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882069ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model\n",
    "model = EnhancedGATModel(input_dim, hidden_dim, output_dim, num_heads)\n",
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "trained_model = train_gat_model(model, train_samples, val_samples, epochs=100, lr=0.001)\n",
    "\n",
    "# Process test data\n",
    "print(\"Processing test data...\")\n",
    "test_data = prepare_eeg_data(test_segments, f'{data_path}/test', distances, threshold)\n",
    "\n",
    "# Make predictions on test data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for data in test_data:\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(x, edge_index)\n",
    "        pred = (out > 0.5).float().cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "\n",
    "# Save predictions\n",
    "test_segments['prediction'] = predictions\n",
    "test_segments.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81066b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09301bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
